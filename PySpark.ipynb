{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MrBC530gmg5"
      },
      "source": [
        "### **Problem** \n",
        "**Our goal is to create a predictive model that can answer the following question:**\n",
        "\n",
        "**What kind of people had a better chance of surviving?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhBfwzBgioTD"
      },
      "source": [
        "**Data about passengers:**\n",
        "*   Name\n",
        "*   Age\n",
        "*   Gender.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIEH8iZqi-sk"
      },
      "source": [
        "## Install and Import Libraries\n",
        "Let's install PySpark:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hv6kLBmgE4i",
        "outputId": "1272a30f-9d03-47fd-c887-363cc03f9c2d"
      },
      "source": [
        "!pip install pyspark "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 48 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 47.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=c84dc718df9d35ef49861fe803b2ffa6e2ec905d502ef51ba3a0bdcd4512ccbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDp80mG9jmfU"
      },
      "source": [
        "## Build Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttzML9fpjE5a"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Big Data\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiqECDzLj1Mg"
      },
      "source": [
        "## Data Loading\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn-hxNggkTqV"
      },
      "source": [
        "You have two datasets: \n",
        "* Train  \n",
        "* Test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8-A8M7QmKDJ"
      },
      "source": [
        "Read two datasets: \n",
        "* Train\n",
        "* Test.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx2qAccBk15y"
      },
      "source": [
        "train = spark.read.csv(\"/content/train.csv\", header=\"true\", inferSchema=\"true\")\n",
        "test = spark.read.csv(\"/content/test.csv\", header=\"true\", inferSchema=\"true\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj2ANTnWmSCq"
      },
      "source": [
        "Let's work with train dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5mWJR30lNs5"
      },
      "source": [
        "**Confirm if this is a dataframe or not:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEYTePrzk9yl",
        "outputId": "5dcd2cdf-2086-410e-d07d-90516c0a2c27"
      },
      "source": [
        "type(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvLJElPrlT4i"
      },
      "source": [
        "**Show 5 rows.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYwhqvV8lnO0",
        "outputId": "47f5faa1-81f7-47b8-9889-5989b2e2587c"
      },
      "source": [
        "train.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QIYVxRXlnnw"
      },
      "source": [
        "**Display schema for the dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcvERiICl1Ep",
        "outputId": "0a324737-5e32-4feb-a659-db3e50b647a7"
      },
      "source": [
        "train.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmE3Wd80l1S6"
      },
      "source": [
        "**Statistical summary:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNY0SItol5Mo",
        "outputId": "97411e17-4220-49bb-bc55-6266e124355f"
      },
      "source": [
        "train.describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
            "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
            "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
            "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
            "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiFaIEQTl70_"
      },
      "source": [
        "## EDA - Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSNPOnP8mw2Q"
      },
      "source": [
        "**Display count for the train dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrtpG11Fl9HM",
        "outputId": "1a272a27-4960-4727-fe52-d2202de59f8f"
      },
      "source": [
        "train_count = train.count()\n",
        "print(train_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_6nnTfxm9_x"
      },
      "source": [
        "**Can you answer this question:** \n",
        "\n",
        "**How many people survived, and how many didn't survive?** \n",
        "\n",
        "**Please save data in a variable.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDoqPwyomYxA"
      },
      "source": [
        "# Answer by code\n",
        "\n",
        "survived_groupped_df = train.groupBy(\"Survived\").count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8DUtZXPn46m"
      },
      "source": [
        "**Display your result:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XHAK8ceoCMU",
        "outputId": "44ffe6cf-0661-488c-f218-537542971dc7"
      },
      "source": [
        "survived_groupped_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|Survived|count|\n",
            "+--------+-----+\n",
            "|       1|  342|\n",
            "|       0|  549|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygsg7wQqor9a"
      },
      "source": [
        "**Can you display your answer in ratio form?(Hint: Use UDF. This is a hint you can use any method.)**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uiaN29PoQnf"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import DoubleType, StringType, StructType, StructField\n",
        "getRatio = F.udf(lambda x: round(x/train_count,2), DoubleType())\n",
        "survived_groupped_df = survived_groupped_df.withColumn(\"Ratio\", getRatio('count'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvzEwesgoQ3s",
        "outputId": "58db0fbe-35be-4bef-c8fe-2f0de13c37d8"
      },
      "source": [
        "survived_groupped_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+-----+\n",
            "|Survived|count|Ratio|\n",
            "+--------+-----+-----+\n",
            "|       1|  342| 0.38|\n",
            "|       0|  549| 0.62|\n",
            "+--------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7Aker_lp1h4"
      },
      "source": [
        "**Can you get the number of males and females?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XllkDlo3ongJ",
        "outputId": "804e0f84-2fb1-4aeb-fab1-ad77d62627b7"
      },
      "source": [
        "gender_grouped_df=train.groupBy(\"Sex\").count()\n",
        "gender_grouped_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|   Sex|count|\n",
            "+------+-----+\n",
            "|female|  314|\n",
            "|  male|  577|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QdiwwkOqDKF"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import DoubleType, StringType, StructType, StructField\n",
        "getRatio = F.udf(lambda x: round(x/train_count,2), DoubleType())\n",
        "gender_grouped_df = gender_grouped_df.withColumn(\"Ratio of Gender\", getRatio('count'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mw1zL_EqZt3",
        "outputId": "f6b08636-d8e7-403c-9c01-0dc5f8cccbe2"
      },
      "source": [
        "gender_grouped_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+---------------+\n",
            "|   Sex|count|Ratio of Gender|\n",
            "+------+-----+---------------+\n",
            "|female|  314|           0.35|\n",
            "|  male|  577|           0.65|\n",
            "+------+-----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHFaJ15zqtEV"
      },
      "source": [
        "**1. What is the average number of survivors of each gender?**\n",
        "\n",
        "**2. What is the number of survivors of each gender?**\n",
        "\n",
        "(Hint: Group by the \"sex\" column. This is a hint you can use any method.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUikH7MUqdKq",
        "outputId": "9a7a637a-4d18-4d09-df5f-f68137f35155"
      },
      "source": [
        "train.groupBy(\"Sex\").agg(F.mean('Survived'), F.sum('Survived')).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+-------------+\n",
            "|   Sex|      avg(Survived)|sum(Survived)|\n",
            "+------+-------------------+-------------+\n",
            "|female| 0.7420382165605095|          233|\n",
            "|  male|0.18890814558058924|          109|\n",
            "+------+-------------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCEdYNdArtRN"
      },
      "source": [
        "**Create temporary view PySpark:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjlK6HDUqsI5"
      },
      "source": [
        "train.createOrReplaceTempView(\"train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXNePifnshHr"
      },
      "source": [
        "**How many people survived, and how many didn't survive? By SQL:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HxfPRTMslqk",
        "outputId": "99d81a8c-1ea8-4ce2-dbd7-140116225f51"
      },
      "source": [
        "spark.sql(\"SELECT count(Survived) FROM train GROUP BY Survived\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|count(Survived)|\n",
            "+---------------+\n",
            "|            342|\n",
            "|            549|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVCdY6EasFWV"
      },
      "source": [
        "**Can you display the number of survivors from each gender as a ratio?**\n",
        "\n",
        "(Hint: Group by \"sex\" column. This is a hint you can use any method.)\n",
        "\n",
        "**Can you do this via SQL?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xQc3pUUr3HF",
        "outputId": "f4bc1cbc-0cf3-4b9a-fe0c-03319f862210"
      },
      "source": [
        "spark.sql(\"SELECT Sex, round(SUM(Survived)/count(1),2) as ratio  FROM train GROUP BY Sex\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|   Sex|ratio|\n",
            "+------+-----+\n",
            "|female| 0.74|\n",
            "|  male| 0.19|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJYwkDToOfzP"
      },
      "source": [
        "**Display a ratio for \"p-class\": SUM(Survived)/count for p-class**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mscs2mDFdFsD",
        "outputId": "73306be7-7316-4258-bdaa-b037f553ada7"
      },
      "source": [
        "spark.sql(\"SELECT Pclass, round(SUM(Survived)/count(1),2) as ratio  FROM train GROUP BY Pclass\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Pclass|ratio|\n",
            "+------+-----+\n",
            "|     1| 0.63|\n",
            "|     3| 0.24|\n",
            "|     2| 0.47|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX0klxwAvg6J"
      },
      "source": [
        "**Let's take a break and continue after this.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ctM9t8atxJl"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CfanZTCt6Wk"
      },
      "source": [
        "**First and foremost, we must merge both the train and test datasets. (Hint: The union function can do this.)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nm8S1K0r4uY"
      },
      "source": [
        "combined = train.union(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI7AD8FLz3iO"
      },
      "source": [
        "**Display count:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4rd9e6nzzr5",
        "outputId": "f833af4f-f218-44d3-b15e-b7ae5394c7e6"
      },
      "source": [
        "combined.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1329"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R4Miuy0z_uP"
      },
      "source": [
        "**Can you define the number of null values in each column?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LMOalKBxhpD",
        "outputId": "7ea45848-1bef-41e3-f750-ebc23535bba7"
      },
      "source": [
        "null_columns = []\n",
        "for col_name in combined.columns:\n",
        "    null_values = combined.where(F.col(col_name).isNull()).count()\n",
        "    if(null_values > 0):\n",
        "        null_columns.append((col_name, null_values))\n",
        "print(null_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Age', 265), ('Cabin', 1021), ('Embarked', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBX8cJ000aqe"
      },
      "source": [
        "**Create Dataframe for null values**\n",
        "\n",
        "1. Column\n",
        "2. Number of missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITmyUelNxjJM",
        "outputId": "c82efee6-218c-4c91-9383-53cee7f6a2ca"
      },
      "source": [
        "spark.createDataFrame(null_columns, ['column', 'missing_value']).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+\n",
            "|  column|missing_value|\n",
            "+--------+-------------+\n",
            "|     Age|          265|\n",
            "|   Cabin|         1021|\n",
            "|Embarked|            3|\n",
            "+--------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuKrOi5a0-Ma"
      },
      "source": [
        "## Preprocessing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVQlr9vDy7Y4"
      },
      "source": [
        "**Create Temporary view PySpark:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs3yeXhGI8rv"
      },
      "source": [
        "combined.createOrReplaceTempView(\"combined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txa8NZIO1JaP"
      },
      "source": [
        "**Can you show the \"name\" column from your temporary table?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7yXqJoJy35k",
        "outputId": "3476794a-d4c8-4e98-af98-b7b1bb823c7f"
      },
      "source": [
        "spark.sql(\"SELECT Name FROM combined\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                Name|\n",
            "+--------------------+\n",
            "|Braund, Mr. Owen ...|\n",
            "|Cumings, Mrs. Joh...|\n",
            "|Heikkinen, Miss. ...|\n",
            "|Futrelle, Mrs. Ja...|\n",
            "|Allen, Mr. Willia...|\n",
            "|    Moran, Mr. James|\n",
            "|McCarthy, Mr. Tim...|\n",
            "|Palsson, Master. ...|\n",
            "|Johnson, Mrs. Osc...|\n",
            "|Nasser, Mrs. Nich...|\n",
            "|Sandstrom, Miss. ...|\n",
            "|Bonnell, Miss. El...|\n",
            "|Saundercock, Mr. ...|\n",
            "|Andersson, Mr. An...|\n",
            "|Vestrom, Miss. Hu...|\n",
            "|Hewlett, Mrs. (Ma...|\n",
            "|Rice, Master. Eugene|\n",
            "|Williams, Mr. Cha...|\n",
            "|Vander Planke, Mr...|\n",
            "|Masselmani, Mrs. ...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F0F9cTZ2Cuz"
      },
      "source": [
        "**Run this code:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kx6OcB-2BBT"
      },
      "source": [
        "combined = combined.withColumn('Title',F.regexp_extract(F.col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
        "combined.createOrReplaceTempView('combined')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbZeUWS12r59"
      },
      "source": [
        "**Display the \"title\" column and count \"Title\" column:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGkFMtlp1FAI",
        "outputId": "f1955678-27e4-4d16-bb89-6ff8d307cadc"
      },
      "source": [
        "spark.sql(\"SELECT Title,count(1)  FROM combined GROUP BY Title\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+\n",
            "|   Title|count(1)|\n",
            "+--------+--------+\n",
            "|     Don|       1|\n",
            "|    Miss|     257|\n",
            "|Countess|       2|\n",
            "|     Col|       4|\n",
            "|     Rev|       9|\n",
            "|    Lady|       2|\n",
            "|  Master|      56|\n",
            "|     Mme|       1|\n",
            "|    Capt|       2|\n",
            "|      Mr|     786|\n",
            "|      Dr|      11|\n",
            "|     Mrs|     186|\n",
            "|     Sir|       2|\n",
            "|Jonkheer|       2|\n",
            "|    Mlle|       4|\n",
            "|   Major|       3|\n",
            "|      Ms|       1|\n",
            "+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLBQDKYu4JOa"
      },
      "source": [
        "**We can see that Dr, Rev, Major, Col, Mlle, Capt, Don, Jonkheer, Countess, Ms, Sir, Lady, and Mme are really rare titles, so create Dictionary and set the value to \"rare\".**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjnx5l5r2Qaf"
      },
      "source": [
        "titles_map = {\n",
        " 'Capt': 'Rare',\n",
        " 'Col': 'Rare',\n",
        " 'Don': 'Rare',\n",
        " 'Dona': 'Rare',\n",
        " 'Dr': 'Rare',\n",
        " 'Jonkheer':'Rare' ,\n",
        " 'Lady': 'Rare',\n",
        " 'Major': 'Rare',\n",
        " 'Master': 'Master',\n",
        " 'Miss': 'Miss',\n",
        " 'Mlle': 'Rare',\n",
        " 'Mme': 'Rare',\n",
        " 'Mr': 'Mr',\n",
        " 'Mrs': 'Mrs',\n",
        " 'Ms': 'Rare',\n",
        " 'Rev': 'Rare',\n",
        " 'Sir': 'Rare',\n",
        " 'Countess': 'Rare'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wrE95Cv7Oqh"
      },
      "source": [
        "**Run the function:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdDbWuDl7Pf4"
      },
      "source": [
        "def impute_title(title):\n",
        "    return titles_map[title]# Title_map is your dictionary. please change this name with your dictionary name."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5EQVIhK7a9R"
      },
      "source": [
        "**Apply the function on \"Title\" column using UDF:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBAiIOn77XFa"
      },
      "source": [
        "title_map_func = F.udf(lambda x: impute_title(x), StringType())\n",
        "combined = combined.withColumn('Title', title_map_func('Title'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn8ewllf7kiV"
      },
      "source": [
        "**Display \"Title\" from table and group by \"Title\" column:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9sjQb084GU6",
        "outputId": "92651bec-a689-4245-f6b7-64a5dca6dfda"
      },
      "source": [
        "combined.createOrReplaceTempView('combined')\n",
        "spark.sql(\"SELECT Title FROM combined GROUP BY Title\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "| Title|\n",
            "+------+\n",
            "|  Miss|\n",
            "|Master|\n",
            "|    Mr|\n",
            "|   Mrs|\n",
            "|  Rare|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H45QNLj9vJp"
      },
      "source": [
        "## **Preprocessing Age**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwRAhumK-u__"
      },
      "source": [
        "**Based on the age mean, you will fill in the missing age values:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXYSVzvl4z63",
        "outputId": "e8486503-fb06-4500-a502-333235e3d316"
      },
      "source": [
        "round(spark.sql(\"SELECT AVG(Age) FROM combined\").collect()[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLPivde8_GI-"
      },
      "source": [
        "**Fill missing age with age mean:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBgW8aFD90PA"
      },
      "source": [
        "combined = combined.fillna(30, subset=['Age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGsnUz-m_P95"
      },
      "source": [
        "## **Preprocessing Embarked**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHbbamcXMSYP"
      },
      "source": [
        "**Select Embarked, count them, order by count Desc, and save in grouped_Embarked variable:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-lRu5vc_FW7"
      },
      "source": [
        "grouped_Embarked = spark.sql(\"SELECT Embarked,count(1) as count_it FROM combined GROUP BY Embarked ORDER BY count_it DESC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1qf5u2IOQrx"
      },
      "source": [
        "**Show groupped_Embarked:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSFNDTNg_erb",
        "outputId": "9f84fc63-ef33-4eba-829d-6648b22bf8cb"
      },
      "source": [
        "grouped_Embarked.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+\n",
            "|Embarked|count_it|\n",
            "+--------+--------+\n",
            "|       S|     962|\n",
            "|       C|     253|\n",
            "|       Q|     111|\n",
            "|    null|       3|\n",
            "+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzQWYgKBMrbp"
      },
      "source": [
        "**Get max of groupped_Embarked:** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu46QWrn_gCX"
      },
      "source": [
        "embarked_mode = grouped_Embarked.collect()[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLYj4F7E_iqb",
        "outputId": "a930f42c-72dc-4156-adfe-05b74bdf4725"
      },
      "source": [
        "print(embarked_mode)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8vhoEs8N2w_"
      },
      "source": [
        "**Fill missing values with max 'S' of grouped_Embarked:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdzQCRud_mAa"
      },
      "source": [
        "combined = combined.fillna(embarked_mode, subset=['Embarked'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEcdV5Vb_qR_"
      },
      "source": [
        "## **Preprocessing Cabin**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BQzPs7tqhpA"
      },
      "source": [
        "**Replace \"cabin\" column with first char from the string:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b6L5pK0_nQz"
      },
      "source": [
        "combined = combined.withColumn(\"Cabin\", combined.Cabin.substr(0, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H8XshnYj4k2"
      },
      "source": [
        "**Show the result:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJUQwnG1Oj2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba95327-f778-4638-f706-0bbdcf8dbcf7"
      },
      "source": [
        "combined.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Title|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|    Mr|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|    C|       C|   Mrs|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|  Miss|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|    C|       S|   Mrs|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|    Mr|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|30.0|    0|    0|          330877| 8.4583| null|       Q|    Mr|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|    E|       S|    Mr|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|Master|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|   Mrs|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|   Mrs|\n",
            "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|    G|       S|  Miss|\n",
            "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|    C|       S|  Miss|\n",
            "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|    Mr|\n",
            "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|    Mr|\n",
            "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|  Miss|\n",
            "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|   Mrs|\n",
            "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|Master|\n",
            "|         18|       1|     2|Williams, Mr. Cha...|  male|30.0|    0|    0|          244373|   13.0| null|       S|    Mr|\n",
            "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|   Mrs|\n",
            "|         20|       1|     3|Masselmani, Mrs. ...|female|30.0|    0|    0|            2649|  7.225| null|       C|   Mrs|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzSDsWsUj9Im"
      },
      "source": [
        "**Create the temporary view:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR7CXTY7_tMJ"
      },
      "source": [
        "combined.createOrReplaceTempView('combined')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv7lfQFkrLlN"
      },
      "source": [
        "**Select \"Cabin\" column, count Cabin column, Group by \"Cabin\" column, Order By count DESC**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0tZG_mvrKXv",
        "outputId": "dface332-d70c-4757-8dce-912450f36e4a"
      },
      "source": [
        "groupped_cabin = spark.sql(\"SELECT Cabin,count(1) as count_it FROM combined GROUP BY Cabin ORDER BY count_it DESC\")\n",
        "groupped_cabin.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+\n",
            "|Cabin|count_it|\n",
            "+-----+--------+\n",
            "| null|    1021|\n",
            "|    C|      82|\n",
            "|    B|      77|\n",
            "|    D|      52|\n",
            "|    E|      51|\n",
            "|    A|      23|\n",
            "|    F|      18|\n",
            "|    G|       4|\n",
            "|    T|       1|\n",
            "+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GR6j0LOsB4y"
      },
      "source": [
        "**Fill missing values with \"U\":**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwq5CHEz_up_"
      },
      "source": [
        "combined = combined.fillna('U', subset=['Cabin'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRnhA_5-0Hi4"
      },
      "source": [
        "**StringIndexer: A label indexer that maps a string column of labels to an ML column of label indices. If the input column is numeric, we cast it to string and index the string values. The indices are in [0, numLabels). By default, this is ordered by label frequencies so the most frequent label gets index 0. The ordering behavior is controlled by setting stringOrderType. Its default value is ‘frequencyDesc’.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RIKlOX71GQ-"
      },
      "source": [
        "**StringIndexer(inputCol=None, outputCol=None)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXhtC8jH_xHE"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler,OneHotEncoder\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA51kFoMEDbt",
        "outputId": "4055cc07-b81f-4e16-cacc-a3795dc3235e"
      },
      "source": [
        "categoricalCols = [field for (field, dataType) in combined.dtypes\n",
        "                   if dataType == \"string\"]\n",
        "categoricalCols\n",
        "            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Title']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVj3iumKAiyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a5aa08-78c9-43f1-f12d-7d8a8f833dba"
      },
      "source": [
        "indexOutputCols = [x + \"_Index\" for x in categoricalCols]\n",
        "indexOutputCols\n",
        "oheOutputCols = [x + \"_OHE\" for x in categoricalCols]\n",
        "oheOutputCols"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name_OHE', 'Sex_OHE', 'Ticket_OHE', 'Cabin_OHE', 'Embarked_OHE', 'Title_OHE']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DECL9yCK3JZ"
      },
      "source": [
        "**OneHotEncoder(inputCols=None, outputCols=None)**\n",
        "\n",
        "A one-hot encoder that maps a column of category indices to a column of binary vectors, with at most a single one-value per row that indicates the input category index. For example with 5 categories, an input value of 2.0 would map to an output vector of [0.0, 0.0, 1.0, 0.0]. The last category is not included by default (configurable via dropLast), because it makes the vector entries sum up to one, and hence linearly dependent. So an input value of 4.0 maps to [0.0, 0.0, 0.0, 0.0]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMB6ESWEEWJe"
      },
      "source": [
        "stringIndexer = StringIndexer(inputCols=categoricalCols,\n",
        "                             outputCols=indexOutputCols,\n",
        "                             handleInvalid='skip')\n",
        "oheEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
        "                          outputCols=oheOutputCols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FsiLsd9452v"
      },
      "source": [
        "**VectorAssembler: VectorAssembler(*, inputCols=None, outputCol=\"features\")**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiIo669gAmHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c2f75e-c7ce-4a64-ccc8-43bbcc441fda"
      },
      "source": [
        "numericCols = [field for (field,dataType) in combined.dtypes\n",
        "              if ((dataType=='double')& (field!='Survived'))]\n",
        "numericCols"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Age', 'Fare']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FylfWcveArhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052618a6-c6c7-4139-e233-0a375f3a077f"
      },
      "source": [
        "assemblerInputs = oheOutputCols + numericCols\n",
        "assemblerInputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name_OHE',\n",
              " 'Sex_OHE',\n",
              " 'Ticket_OHE',\n",
              " 'Cabin_OHE',\n",
              " 'Embarked_OHE',\n",
              " 'Title_OHE',\n",
              " 'Age',\n",
              " 'Fare']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbZ_FxHCAstl"
      },
      "source": [
        "vecAssembler = VectorAssembler(inputCols=numericCols,outputCol='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRt1hH-eL5JL"
      },
      "source": [
        "**Use randomSplit function and split data to x_train, and X_test with 80% and 20% Consecutive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C11xf1iAzKp"
      },
      "source": [
        "X_train, X_test = combined.randomSplit([0.8, 0.2],seed = 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0c_Hf_b0R12"
      },
      "source": [
        "**Pipeline: ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "173bXyyBL5JL"
      },
      "source": [
        "**Build RandomForestClassifier model and use pipeline to fit and transform then display \"prediction, Survived, features\" columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIDSJzgA035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a5d84fc-1d9d-4dd9-af51-c3c5b1bcff28"
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'Survived')\n",
        "pipeline = Pipeline(stages=[stringIndexer,oheEncoder,vecAssembler,rf])\n",
        "\n",
        "predictions = pipeline.fit(X_train).transform(X_test)\n",
        "\n",
        "combined.show()\n",
        "predictions.select(\"prediction\", \"Survived\", \"features\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Title|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|    U|       S|    Mr|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|    C|       C|   Mrs|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|    U|       S|  Miss|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|    C|       S|   Mrs|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|    U|       S|    Mr|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|30.0|    0|    0|          330877| 8.4583|    U|       Q|    Mr|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|    E|       S|    Mr|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|    U|       S|Master|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|    U|       S|   Mrs|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|    U|       C|   Mrs|\n",
            "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|    G|       S|  Miss|\n",
            "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|    C|       S|  Miss|\n",
            "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|    U|       S|    Mr|\n",
            "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|    U|       S|    Mr|\n",
            "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|    U|       S|  Miss|\n",
            "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|    U|       S|   Mrs|\n",
            "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|    U|       Q|Master|\n",
            "|         18|       1|     2|Williams, Mr. Cha...|  male|30.0|    0|    0|          244373|   13.0|    U|       S|    Mr|\n",
            "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|    U|       S|   Mrs|\n",
            "|         20|       1|     3|Masselmani, Mrs. ...|female|30.0|    0|    0|            2649|  7.225|    U|       C|   Mrs|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----------+--------+--------------+\n",
            "|prediction|Survived|      features|\n",
            "+----------+--------+--------------+\n",
            "|       1.0|       1|[49.0,89.1042]|\n",
            "|       0.0|       0|  [65.0,26.55]|\n",
            "|       0.0|       1|[30.0,51.8625]|\n",
            "|       0.0|       1|   [50.0,10.5]|\n",
            "|       0.0|       0|  [30.0,7.725]|\n",
            "|       0.0|       0|   [30.0,52.0]|\n",
            "|       0.0|       1| [63.0,9.5875]|\n",
            "|       1.0|       1|[25.0,91.0792]|\n",
            "|       0.0|       0|[30.0,25.4667]|\n",
            "|       0.0|       0|   [30.0,8.05]|\n",
            "|       0.0|       1|    [9.0,15.9]|\n",
            "|       1.0|       1|[54.0,78.2667]|\n",
            "|       0.0|       1|  [30.0,26.55]|\n",
            "|       1.0|       1|[26.0,56.4958]|\n",
            "|       0.0|       0| [32.0,7.8958]|\n",
            "|       0.0|       0|  [30.0,7.225]|\n",
            "|       0.0|       0|   [40.5,7.75]|\n",
            "|       0.0|       0|  [9.0,31.275]|\n",
            "|       0.0|       1|   [32.0,26.0]|\n",
            "|       1.0|       0|[50.0,106.425]|\n",
            "+----------+--------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSXEI8-r8bKY"
      },
      "source": [
        "**Use MulticlassClassificationEvaluator and set the \"labelCol\" to \"Survived\",  \"predictionCol\" to \"prediction\", \"metricName\" to \"accuracy\"** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QakIxjnDA2Ri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "f0d56881-fe8c-4ba8-fbf2-07684ff4e30c"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "print(\"Accuracy : \" + str(evaluator.evaluate(predictions)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a79d043d4d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl0UAKCaBDO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "809e79ea-c5ed-45c8-c7d8-4d4d101677fe"
      },
      "source": [
        "test = test.drop('Survived')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c9d331c9f845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    }
  ]
}